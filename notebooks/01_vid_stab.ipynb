{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f675ba9-7fd3-4f59-b5b9-8df3caefda40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /home/uday/repo/rev-3d/.venv/lib/python3.12/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /home/uday/repo/rev-3d/.venv/lib/python3.12/site-packages (from opencv-python) (2.2.3)\n",
      "Requirement already satisfied: numpy in /home/uday/repo/rev-3d/.venv/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: ffmpeg-python in /home/uday/repo/rev-3d/.venv/lib/python3.12/site-packages (0.2.0)\n",
      "Requirement already satisfied: future in /home/uday/repo/rev-3d/.venv/lib/python3.12/site-packages (from ffmpeg-python) (1.0.0)\n",
      "Requirement already satisfied: tqdm in /home/uday/repo/rev-3d/.venv/lib/python3.12/site-packages (4.67.1)\n",
      "Requirement already satisfied: matplotlib in /home/uday/repo/rev-3d/.venv/lib/python3.12/site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/uday/repo/rev-3d/.venv/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/uday/repo/rev-3d/.venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/uday/repo/rev-3d/.venv/lib/python3.12/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/uday/repo/rev-3d/.venv/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/uday/repo/rev-3d/.venv/lib/python3.12/site-packages (from matplotlib) (2.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/uday/repo/rev-3d/.venv/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/uday/repo/rev-3d/.venv/lib/python3.12/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/uday/repo/rev-3d/.venv/lib/python3.12/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/uday/repo/rev-3d/.venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/uday/repo/rev-3d/.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Collecting vidgear\n",
      "  Downloading vidgear-0.3.3-py3-none-any.whl.metadata (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Collecting colorlog (from vidgear)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting cython (from vidgear)\n",
      "  Downloading Cython-3.0.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: numpy in /home/uday/repo/rev-3d/.venv/lib/python3.12/site-packages (from vidgear) (2.2.3)\n",
      "Requirement already satisfied: requests in /home/uday/repo/rev-3d/.venv/lib/python3.12/site-packages (from vidgear) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /home/uday/repo/rev-3d/.venv/lib/python3.12/site-packages (from vidgear) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/uday/repo/rev-3d/.venv/lib/python3.12/site-packages (from requests->vidgear) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/uday/repo/rev-3d/.venv/lib/python3.12/site-packages (from requests->vidgear) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/uday/repo/rev-3d/.venv/lib/python3.12/site-packages (from requests->vidgear) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/uday/repo/rev-3d/.venv/lib/python3.12/site-packages (from requests->vidgear) (2025.1.31)\n",
      "Downloading vidgear-0.3.3-py3-none-any.whl (122 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.0/122.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading Cython-3.0.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "Installing collected packages: cython, colorlog, vidgear\n",
      "Successfully installed colorlog-6.9.0 cython-3.0.12 vidgear-0.3.3\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install numpy\n",
    "\n",
    "!pip install ffmpeg-python\n",
    "!pip install tqdm\n",
    "\n",
    "!pip install matplotlib\n",
    "\n",
    "!pip install vidgear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4d8083a-ecfe-493c-8843-1f826dabd89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stabilizing ../data/NissanMurano/unstable.mp4 to ../data/NissanMurano/stable_ffmpeg_claude.mp4\n",
      "Step 1: Analyzing video motion...\n",
      "Step 2: Applying stabilization...\n",
      "Stabilization completed. Output saved to ../data/NissanMurano/stable_ffmpeg_claude.mp4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprocessed_dir = os.path.join(\"data/NissanMurano/processed\")\\nif not os.path.exists(processed_dir):\\n    os.makedirs(processed_dir)\\n\\nextract_frames_at_angles(output_file, processed_dir)\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FFmpeg Video Stabilization Implementation\n",
    "# not that goodd\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def stabilize_video_ffmpeg(input_path, output_path, shakiness=5, accuracy=15, stepsize=6, smoothing=10):\n",
    "    \"\"\"\n",
    "    Stabilize video using FFmpeg's vidstab filter.\n",
    "    \n",
    "    Args:\n",
    "        input_path (str): Path to input unstable video\n",
    "        output_path (str): Path to save stabilized video\n",
    "        shakiness (int): How shaky is the video (1-10, default 5)\n",
    "        accuracy (int): Accuracy of motion detection (1-15, default 15)\n",
    "        stepsize (int): Step size of the search process (1-32, default 6)\n",
    "        smoothing (int): How smooth the motion should be (1-100, default 10)\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if stabilization was successful, False otherwise\n",
    "    \"\"\"\n",
    "    print(f\"Stabilizing {input_path} to {output_path}\")\n",
    "    \n",
    "    # Check if input file exists\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"Error: Input file does not exist: {input_path}\")\n",
    "        return False\n",
    "    \n",
    "    # Create a temporary file for the transform data\n",
    "    with tempfile.NamedTemporaryFile(suffix='.trf', delete=False) as tmp_file:\n",
    "        transform_file = tmp_file.name\n",
    "    \n",
    "    try:\n",
    "        # First pass: analyze video and generate transform data\n",
    "        analyze_cmd = [\n",
    "            'ffmpeg',\n",
    "            '-i', input_path,\n",
    "            '-vf', f'vidstabdetect=shakiness={shakiness}:accuracy={accuracy}:stepsize={stepsize}:mincontrast=0.3:result={transform_file}',\n",
    "            '-f', 'null', '-'\n",
    "        ]\n",
    "        \n",
    "        print(\"Step 1: Analyzing video motion...\")\n",
    "        subprocess.run(analyze_cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        \n",
    "        # Second pass: apply stabilization using the transform data\n",
    "        stabilize_cmd = [\n",
    "            'ffmpeg',\n",
    "            '-i', input_path,\n",
    "            '-vf', f'vidstabtransform=input={transform_file}:zoom=0:smoothing={smoothing}:optalgo=gauss:maxshift=-1:interpol=bilinear',\n",
    "            '-c:v', 'libx264',  # Use x264 codec\n",
    "            '-preset', 'medium',  # Compression preset (adjust as needed)\n",
    "            '-tune', 'film',  # Tune for film content\n",
    "            '-crf', '18',  # Quality (lower is better, 18-28 is typical range)\n",
    "            '-c:a', 'copy',  # Copy audio stream\n",
    "            output_path\n",
    "        ]\n",
    "        \n",
    "        print(\"Step 2: Applying stabilization...\")\n",
    "        subprocess.run(stabilize_cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        \n",
    "        print(f\"Stabilization completed. Output saved to {output_path}\")\n",
    "        return True\n",
    "        \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error during FFmpeg processing: {e}\")\n",
    "        print(f\"Error output: {e.stderr.decode() if e.stderr else 'None'}\")\n",
    "        return False\n",
    "    finally:\n",
    "        # Clean up the temporary transform file\n",
    "        if os.path.exists(transform_file):\n",
    "            os.remove(transform_file)\n",
    "\n",
    "# Function to test different parameters\n",
    "def test_ffmpeg_parameters(input_path, output_dir, parameter_sets):\n",
    "    \"\"\"\n",
    "    Test different parameter sets for FFmpeg stabilization\n",
    "    \n",
    "    Args:\n",
    "        input_path (str): Path to input unstable video\n",
    "        output_dir (str): Directory to save output videos\n",
    "        parameter_sets (list): List of parameter dictionaries\n",
    "    \n",
    "    Returns:\n",
    "        list: Paths to output videos\n",
    "    \"\"\"\n",
    "    output_paths = []\n",
    "    \n",
    "    for i, params in enumerate(parameter_sets):\n",
    "        output_name = f\"stable_ffmpeg_test_{i+1}.mp4\"\n",
    "        output_path = os.path.join(output_dir, output_name)\n",
    "        \n",
    "        print(f\"\\nTest {i+1}: Parameters: {params}\")\n",
    "        success = stabilize_video_ffmpeg(input_path, output_path, **params)\n",
    "        \n",
    "        if success:\n",
    "            output_paths.append(output_path)\n",
    "    \n",
    "    return output_paths\n",
    "\n",
    "# Example usage\n",
    "input_file = \"../data/NissanMurano/unstable.mp4\"\n",
    "output_file = \"../data/NissanMurano/stable_ffmpeg_claude.mp4\"\n",
    "\n",
    "# Make sure the output directory exists\n",
    "output_dir = os.path.dirname(output_file)\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Stabilize with default parameters\n",
    "stabilize_video_ffmpeg(input_file, output_file)\n",
    "\n",
    "# Function to compare visual results\n",
    "def compare_multiple_videos(video_paths, labels, num_frames=5):\n",
    "    \"\"\"\n",
    "    Compare multiple videos side by side\n",
    "    \n",
    "    Args:\n",
    "        video_paths (list): List of paths to videos to compare\n",
    "        labels (list): Labels for each video\n",
    "        num_frames (int): Number of frames to compare\n",
    "    \"\"\"\n",
    "    # Open all videos\n",
    "    caps = [cv2.VideoCapture(path) for path in video_paths]\n",
    "    \n",
    "    # Check if all videos opened successfully\n",
    "    if not all(cap.isOpened() for cap in caps):\n",
    "        print(\"Error: Could not open one or more videos\")\n",
    "        for cap in caps:\n",
    "            cap.release()\n",
    "        return\n",
    "    \n",
    "    # Get minimum frame count across all videos\n",
    "    total_frames = min(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) for cap in caps)\n",
    "    \n",
    "    # Sample frames evenly\n",
    "    frame_indices = np.linspace(0, total_frames-1, num_frames, dtype=int)\n",
    "    \n",
    "    # Set up the plot\n",
    "    n_videos = len(video_paths)\n",
    "    fig, axes = plt.subplots(num_frames, n_videos, figsize=(4*n_videos, 3*num_frames))\n",
    "    \n",
    "    # If there's only one frame to display, make sure axes is properly shaped\n",
    "    if num_frames == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i, frame_idx in enumerate(frame_indices):\n",
    "        for j, cap in enumerate(caps):\n",
    "            # Set frame position\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "            \n",
    "            # Read frame\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            if ret:\n",
    "                # Convert BGR to RGB\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                # Display\n",
    "                axes[i, j].imshow(frame_rgb)\n",
    "                axes[i, j].set_title(f\"{labels[j]}\\nFrame {frame_idx}\")\n",
    "                axes[i, j].axis('off')\n",
    "            else:\n",
    "                axes[i, j].text(0.5, 0.5, \"Frame not available\", \n",
    "                               horizontalalignment='center',\n",
    "                               verticalalignment='center')\n",
    "                axes[i, j].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Release all video captures\n",
    "    for cap in caps:\n",
    "        cap.release()\n",
    "\n",
    "# Uncomment to test different parameter sets\n",
    "\"\"\"\n",
    "parameter_sets = [\n",
    "    {\"shakiness\": 3, \"accuracy\": 10, \"stepsize\": 6, \"smoothing\": 5},\n",
    "    {\"shakiness\": 5, \"accuracy\": 15, \"stepsize\": 6, \"smoothing\": 10},\n",
    "    {\"shakiness\": 8, \"accuracy\": 15, \"stepsize\": 4, \"smoothing\": 15}\n",
    "]\n",
    "\n",
    "output_dir = os.path.dirname(output_file)\n",
    "output_paths = test_ffmpeg_parameters(input_file, output_dir, parameter_sets)\n",
    "\n",
    "# Compare results\n",
    "compare_multiple_videos(\n",
    "    [input_file] + output_paths,\n",
    "    [\"Original\"] + [f\"Test {i+1}\" for i in range(len(parameter_sets))],\n",
    "    num_frames=3\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Function to extract frames at specific angles\n",
    "def extract_frames_at_angles(input_path, output_dir, num_frames=36):\n",
    "    \"\"\"\n",
    "    Extract frames from a video at specific angles assuming a full 360° rotation\n",
    "    \n",
    "    Args:\n",
    "        input_path (str): Path to input video\n",
    "        output_dir (str): Directory to save extracted frames\n",
    "        num_frames (int): Number of frames to extract (default 36 for 10° intervals)\n",
    "    \n",
    "    Returns:\n",
    "        list: Paths to extracted frames\n",
    "    \"\"\"\n",
    "    print(f\"Extracting {num_frames} frames from {input_path}\")\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Open the video\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Cannot open video file {input_path}\")\n",
    "        return []\n",
    "    \n",
    "    # Get video properties\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Calculate frame indices to extract (evenly distributed)\n",
    "    frame_indices = np.linspace(0, total_frames-1, num_frames, dtype=int)\n",
    "    \n",
    "    extracted_paths = []\n",
    "    \n",
    "    for i, frame_idx in enumerate(frame_indices):\n",
    "        # Set frame position\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        \n",
    "        # Read frame\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if ret:\n",
    "            # Calculate angle (0° to 350° for 36 frames)\n",
    "            angle = (i * 360) // num_frames\n",
    "            \n",
    "            # Save frame\n",
    "            output_path = os.path.join(output_dir, f\"img_{i+1:02d}_{angle:03d}deg.png\")\n",
    "            cv2.imwrite(output_path, frame)\n",
    "            \n",
    "            extracted_paths.append(output_path)\n",
    "            print(f\"Extracted frame {i+1}/{num_frames} - {angle}° angle\")\n",
    "    \n",
    "    cap.release()\n",
    "    return extracted_paths\n",
    "\n",
    "# Uncomment to extract frames after stabilization\n",
    "\"\"\"\n",
    "processed_dir = os.path.join(\"data/NissanMurano/processed\")\n",
    "if not os.path.exists(processed_dir):\n",
    "    os.makedirs(processed_dir)\n",
    "\n",
    "extract_frames_at_angles(output_file, processed_dir)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0beee54f-1f86-405e-9c6a-88634fd85095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: ../data/NissanMurano/stabilization_tests\n",
      "Stabilizing with config: moderate_smooth\n",
      "Parameters: shakiness=8, accuracy=15, stepsize=4, smoothing=30, zoom=1.05, maxshift=-1, optalgo=gauss, interpol=bicubic, tripod=0, crf=15\n",
      "Step 1: Analyzing video motion for moderate_smooth...\n",
      "Step 2: Applying stabilization for moderate_smooth...\n",
      "Stabilization completed for moderate_smooth. Output saved to ../data/NissanMurano/stabilization_tests/stable_moderate_smooth.mp4\n",
      "Completed moderate_smooth in 93.97 seconds\n",
      "--------------------------------------------------\n",
      "Stabilizing with config: higher_smooth\n",
      "Parameters: shakiness=9, accuracy=15, stepsize=4, smoothing=40, zoom=1.1, maxshift=-1, optalgo=gauss, interpol=bicubic, tripod=0, crf=15\n",
      "Step 1: Analyzing video motion for higher_smooth...\n",
      "Step 2: Applying stabilization for higher_smooth...\n",
      "Stabilization completed for higher_smooth. Output saved to ../data/NissanMurano/stabilization_tests/stable_higher_smooth.mp4\n",
      "Completed higher_smooth in 91.34 seconds\n",
      "--------------------------------------------------\n",
      "Stabilizing with config: tripod_mode\n",
      "Parameters: shakiness=9, accuracy=15, stepsize=4, smoothing=30, zoom=1.15, maxshift=-1, optalgo=gauss, interpol=bicubic, tripod=1, crf=15\n",
      "Step 1: Analyzing video motion for tripod_mode...\n",
      "Step 2: Applying stabilization for tripod_mode...\n",
      "Stabilization completed for tripod_mode. Output saved to ../data/NissanMurano/stabilization_tests/stable_tripod_mode.mp4\n",
      "Completed tripod_mode in 93.70 seconds\n",
      "--------------------------------------------------\n",
      "Stabilizing with config: max_smooth_quality\n",
      "Parameters: shakiness=10, accuracy=15, stepsize=4, smoothing=50, zoom=1.12, maxshift=-1, optalgo=gauss, interpol=bicubic, tripod=0, crf=15\n",
      "Step 1: Analyzing video motion for max_smooth_quality...\n",
      "Step 2: Applying stabilization for max_smooth_quality...\n",
      "Stabilization completed for max_smooth_quality. Output saved to ../data/NissanMurano/stabilization_tests/stable_max_smooth_quality.mp4\n",
      "Completed max_smooth_quality in 94.21 seconds\n",
      "--------------------------------------------------\n",
      "Stabilizing with config: balanced_tripod\n",
      "Parameters: shakiness=10, accuracy=15, stepsize=6, smoothing=40, zoom=1.15, maxshift=40, optalgo=gauss, interpol=bicubic, tripod=1, crf=15\n",
      "Step 1: Analyzing video motion for balanced_tripod...\n",
      "Step 2: Applying stabilization for balanced_tripod...\n",
      "Stabilization completed for balanced_tripod. Output saved to ../data/NissanMurano/stabilization_tests/stable_balanced_tripod.mp4\n",
      "Completed balanced_tripod in 86.42 seconds\n",
      "--------------------------------------------------\n",
      "Stabilizing with config: max_stable_balanced\n",
      "Parameters: shakiness=10, accuracy=15, stepsize=6, smoothing=60, zoom=1.2, maxshift=30, optalgo=gauss, interpol=bicubic, tripod=1, crf=18\n",
      "Step 1: Analyzing video motion for max_stable_balanced...\n",
      "Step 2: Applying stabilization for max_stable_balanced...\n",
      "Stabilization completed for max_stable_balanced. Output saved to ../data/NissanMurano/stabilization_tests/stable_max_stable_balanced.mp4\n",
      "Completed max_stable_balanced in 84.21 seconds\n",
      "--------------------------------------------------\n",
      "\n",
      "All test configurations completed. Check the 'stabilization_tests' directory for results.\n",
      "Configurations tested:\n",
      "1. moderate_smooth - Original with increased smoothing\n",
      "2. higher_smooth - Higher smoothing with slight zoom\n",
      "3. tripod_mode - Tripod mode with moderate smoothing\n",
      "4. max_smooth_quality - Maximum smoothing with quality focus\n",
      "5. balanced_tripod - Balanced approach with tripod influence\n",
      "6. max_stable_balanced - Maximum stabilization with quality balance\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# compare a few configs for best quality\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import tempfile\n",
    "import time\n",
    "\n",
    "def stabilize_video_ffmpeg(input_path, output_path, config_name, shakiness=8, accuracy=15, stepsize=4, smoothing=15, \n",
    "                          zoom=1.0, maxshift=-1, optalgo='gauss', interpol='bicubic', tripod=0, crf=15):\n",
    "    \"\"\"\n",
    "    Stabilize video using FFmpeg's vidstab filter with configurable parameters.\n",
    "    \n",
    "    Args:\n",
    "        input_path (str): Path to input unstable video\n",
    "        output_path (str): Path to save stabilized video\n",
    "        config_name (str): Name of this configuration for logging\n",
    "        shakiness (int): How shaky is the video (1-10)\n",
    "        accuracy (int): Accuracy of motion detection (1-15)\n",
    "        stepsize (int): Step size of the search process (1-32)\n",
    "        smoothing (int): How smooth the motion should be (1-100)\n",
    "        zoom (float): Zooming factor to avoid black borders\n",
    "        maxshift (int): Maximum number of pixels to shift frames\n",
    "        optalgo (str): Algorithm for optimization (gauss or avg)\n",
    "        interpol (str): Interpolation method (linear, bilinear, bicubic)\n",
    "        tripod (int): Enable virtual tripod mode (0 or 1)\n",
    "        crf (int): Constant Rate Factor for quality (lower is better)\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if stabilization was successful, False otherwise\n",
    "    \"\"\"\n",
    "    print(f\"Stabilizing with config: {config_name}\")\n",
    "    print(f\"Parameters: shakiness={shakiness}, accuracy={accuracy}, stepsize={stepsize}, smoothing={smoothing}, \"\n",
    "          f\"zoom={zoom}, maxshift={maxshift}, optalgo={optalgo}, interpol={interpol}, tripod={tripod}, crf={crf}\")\n",
    "    \n",
    "    # Check if input file exists\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"Error: Input file does not exist: {input_path}\")\n",
    "        return False\n",
    "    \n",
    "    # Create a temporary file for the transform data\n",
    "    with tempfile.NamedTemporaryFile(suffix='.trf', delete=False) as tmp_file:\n",
    "        transform_file = tmp_file.name\n",
    "    \n",
    "    try:\n",
    "        # First pass: analyze video and generate transform data\n",
    "        analyze_cmd = [\n",
    "            'ffmpeg',\n",
    "            '-i', input_path,\n",
    "            '-vf', f'vidstabdetect=shakiness={shakiness}:accuracy={accuracy}:stepsize={stepsize}:mincontrast=0.3:result={transform_file}',\n",
    "            '-f', 'null', '-'\n",
    "        ]\n",
    "        \n",
    "        print(f\"Step 1: Analyzing video motion for {config_name}...\")\n",
    "        subprocess.run(analyze_cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        \n",
    "        # Second pass: apply stabilization using the transform data\n",
    "        transform_params = f'vidstabtransform=input={transform_file}:zoom={zoom}:smoothing={smoothing}:optalgo={optalgo}:maxshift={maxshift}:interpol={interpol}'\n",
    "        \n",
    "        # Add tripod mode if enabled\n",
    "        if tripod == 1:\n",
    "            transform_params += ':tripod=1'\n",
    "        \n",
    "        stabilize_cmd = [\n",
    "            'ffmpeg',\n",
    "            '-i', input_path,\n",
    "            '-vf', transform_params,\n",
    "            '-c:v', 'libx264',  # Use x264 codec\n",
    "            '-preset', 'slow',  # Slower preset for better quality\n",
    "            '-tune', 'film',    # Tune for film content\n",
    "            '-crf', str(crf),   # Quality setting\n",
    "            '-c:a', 'copy',     # Copy audio stream\n",
    "            output_path\n",
    "        ]\n",
    "        \n",
    "        print(f\"Step 2: Applying stabilization for {config_name}...\")\n",
    "        subprocess.run(stabilize_cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        \n",
    "        print(f\"Stabilization completed for {config_name}. Output saved to {output_path}\")\n",
    "        return True\n",
    "        \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error during FFmpeg processing for {config_name}: {e}\")\n",
    "        print(f\"Error output: {e.stderr.decode() if e.stderr else 'None'}\")\n",
    "        return False\n",
    "    finally:\n",
    "        # Clean up the temporary transform file\n",
    "        if os.path.exists(transform_file):\n",
    "            os.remove(transform_file)\n",
    "\n",
    "def create_test_batch(input_file, base_output_dir):\n",
    "    \"\"\"\n",
    "    Create multiple versions of stabilized video with different configurations\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Path to the unstable input video\n",
    "        base_output_dir (str): Directory to save the output videos\n",
    "    \"\"\"\n",
    "    # Create the test directory if it doesn't exist\n",
    "    test_dir = os.path.join(base_output_dir, \"stabilization_tests\")\n",
    "    if not os.path.exists(test_dir):\n",
    "        os.makedirs(test_dir)\n",
    "        print(f\"Created directory: {test_dir}\")\n",
    "    \n",
    "    # Configuration sets for testing\n",
    "    configs = [\n",
    "        # Config 1: Original with increased smoothing\n",
    "        {\n",
    "            \"name\": \"moderate_smooth\",\n",
    "            \"params\": {\n",
    "                \"shakiness\": 8, \n",
    "                \"accuracy\": 15, \n",
    "                \"stepsize\": 4, \n",
    "                \"smoothing\": 30,  # Increased from 15\n",
    "                \"zoom\": 1.05,    # Slight zoom to avoid borders\n",
    "                \"maxshift\": -1, \n",
    "                \"optalgo\": \"gauss\", \n",
    "                \"interpol\": \"bicubic\",\n",
    "                \"tripod\": 0,\n",
    "                \"crf\": 15\n",
    "            }\n",
    "        },\n",
    "        # Config 2: Higher smoothing with slight tripod effect\n",
    "        {\n",
    "            \"name\": \"higher_smooth\",\n",
    "            \"params\": {\n",
    "                \"shakiness\": 9, \n",
    "                \"accuracy\": 15, \n",
    "                \"stepsize\": 4, \n",
    "                \"smoothing\": 40,  # Higher smoothing\n",
    "                \"zoom\": 1.1,     # More zoom to avoid black borders\n",
    "                \"maxshift\": -1, \n",
    "                \"optalgo\": \"gauss\", \n",
    "                \"interpol\": \"bicubic\",\n",
    "                \"tripod\": 0,\n",
    "                \"crf\": 15\n",
    "            }\n",
    "        },\n",
    "        # Config 3: Tripod mode with moderate smoothing\n",
    "        {\n",
    "            \"name\": \"tripod_mode\",\n",
    "            \"params\": {\n",
    "                \"shakiness\": 9, \n",
    "                \"accuracy\": 15, \n",
    "                \"stepsize\": 4, \n",
    "                \"smoothing\": 30,\n",
    "                \"zoom\": 1.15,    # More zoom to compensate for tripod mode\n",
    "                \"maxshift\": -1, \n",
    "                \"optalgo\": \"gauss\", \n",
    "                \"interpol\": \"bicubic\",\n",
    "                \"tripod\": 1,     # Enable tripod mode\n",
    "                \"crf\": 15\n",
    "            }\n",
    "        },\n",
    "        # Config 4: Max smoothing with quality focus\n",
    "        {\n",
    "            \"name\": \"max_smooth_quality\",\n",
    "            \"params\": {\n",
    "                \"shakiness\": 10, \n",
    "                \"accuracy\": 15, \n",
    "                \"stepsize\": 4, \n",
    "                \"smoothing\": 50,  # Very high smoothing\n",
    "                \"zoom\": 1.12,     # Higher zoom\n",
    "                \"maxshift\": -1, \n",
    "                \"optalgo\": \"gauss\", \n",
    "                \"interpol\": \"bicubic\",\n",
    "                \"tripod\": 0,\n",
    "                \"crf\": 15        # Maintain high quality\n",
    "            }\n",
    "        },\n",
    "        # Config 5: Balanced approach with tripod influence\n",
    "        {\n",
    "            \"name\": \"balanced_tripod\",\n",
    "            \"params\": {\n",
    "                \"shakiness\": 10, \n",
    "                \"accuracy\": 15, \n",
    "                \"stepsize\": 6,   # Increased for more precision\n",
    "                \"smoothing\": 40, \n",
    "                \"zoom\": 1.15,\n",
    "                \"maxshift\": 40,  # Limited max shift\n",
    "                \"optalgo\": \"gauss\", \n",
    "                \"interpol\": \"bicubic\",\n",
    "                \"tripod\": 1,     # Enable tripod mode\n",
    "                \"crf\": 15\n",
    "            }\n",
    "        },\n",
    "        # Config 6: Maximum stabilization with quality balance\n",
    "        {\n",
    "            \"name\": \"max_stable_balanced\",\n",
    "            \"params\": {\n",
    "                \"shakiness\": 10, \n",
    "                \"accuracy\": 15, \n",
    "                \"stepsize\": 6, \n",
    "                \"smoothing\": 60,  # Very high smoothing\n",
    "                \"zoom\": 1.2,      # Higher zoom to avoid borders\n",
    "                \"maxshift\": 30,   # Limited max shift\n",
    "                \"optalgo\": \"gauss\", \n",
    "                \"interpol\": \"bicubic\",\n",
    "                \"tripod\": 1,      # Enable tripod mode\n",
    "                \"crf\": 18         # Slightly lower quality for better performance\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Process each configuration\n",
    "    for config in configs:\n",
    "        # Create output filename with configuration details\n",
    "        output_name = f\"stable_{config['name']}.mp4\"\n",
    "        output_path = os.path.join(test_dir, output_name)\n",
    "        \n",
    "        # Apply stabilization with this configuration\n",
    "        start_time = time.time()\n",
    "        success = stabilize_video_ffmpeg(\n",
    "            input_path=input_file,\n",
    "            output_path=output_path,\n",
    "            config_name=config['name'],\n",
    "            **config['params']\n",
    "        )\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        if success:\n",
    "            print(f\"Completed {config['name']} in {elapsed_time:.2f} seconds\")\n",
    "        else:\n",
    "            print(f\"Failed to process {config['name']}\")\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Extract the directory of the unstable video\n",
    "    input_file = \"../data/NissanMurano/unstable.mp4\"\n",
    "    base_dir = os.path.dirname(input_file)\n",
    "    \n",
    "    # Create test batch\n",
    "    create_test_batch(input_file, base_dir)\n",
    "    \n",
    "    print(\"\\nAll test configurations completed. Check the 'stabilization_tests' directory for results.\")\n",
    "    print(\"Configurations tested:\")\n",
    "    print(\"1. moderate_smooth - Original with increased smoothing\")\n",
    "    print(\"2. higher_smooth - Higher smoothing with slight zoom\")\n",
    "    print(\"3. tripod_mode - Tripod mode with moderate smoothing\")\n",
    "    print(\"4. max_smooth_quality - Maximum smoothing with quality focus\")\n",
    "    print(\"5. balanced_tripod - Balanced approach with tripod influence\")\n",
    "    print(\"6. max_stable_balanced - Maximum stabilization with quality balance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a0b6fcb-6f0b-442d-b609-ab095591d7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stabilizing ../data/NissanMurano/unstable.mp4 to ../data/NissanMurano/stable_max_smoothing.mp4\n",
      "Step 1: Analyzing video motion...\n",
      "Step 2: Applying stabilization...\n",
      "Stabilization completed. Output saved to ../data/NissanMurano/stable_max_smoothing.mp4\n"
     ]
    }
   ],
   "source": [
    "# ffmpeg-claude-max-smooth-quality\n",
    "# FFmpeg Video Stabilization Implementation - Max Smooth Quality\n",
    "# works best - although not perfect\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import tempfile\n",
    "\n",
    "def stabilize_video_ffmpeg(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Stabilize video using FFmpeg's vidstab filter with max smooth quality configuration.\n",
    "    \n",
    "    Args:\n",
    "        input_path (str): Path to input unstable video\n",
    "        output_path (str): Path to save stabilized video\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if stabilization was successful, False otherwise\n",
    "    \"\"\"\n",
    "    print(f\"Stabilizing {input_path} to {output_path}\")\n",
    "    \n",
    "    # Check if input file exists\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"Error: Input file does not exist: {input_path}\")\n",
    "        return False\n",
    "    \n",
    "    # Create a temporary file for the transform data\n",
    "    with tempfile.NamedTemporaryFile(suffix='.trf', delete=False) as tmp_file:\n",
    "        transform_file = tmp_file.name\n",
    "    \n",
    "    try:\n",
    "        # First pass: analyze video and generate transform data\n",
    "        analyze_cmd = [\n",
    "            'ffmpeg',\n",
    "            '-i', input_path,\n",
    "            '-vf', f'vidstabdetect=shakiness=10:accuracy=15:stepsize=4:mincontrast=0.3:result={transform_file}',\n",
    "            '-f', 'null', '-'\n",
    "        ]\n",
    "        \n",
    "        print(\"Step 1: Analyzing video motion...\")\n",
    "        subprocess.run(analyze_cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        \n",
    "        # Second pass: apply stabilization using the transform data\n",
    "        stabilize_cmd = [\n",
    "            'ffmpeg',\n",
    "            '-i', input_path,\n",
    "            '-vf', f'vidstabtransform=input={transform_file}:zoom=1.12:smoothing=50:optalgo=gauss:maxshift=-1:interpol=bicubic',\n",
    "            '-c:v', 'libx264',  # Use x264 codec\n",
    "            '-preset', 'slow',  # Slower preset for better quality\n",
    "            '-tune', 'film',    # Tune for film content\n",
    "            '-crf', '15',       # Higher quality (lower value)\n",
    "            '-c:a', 'copy',     # Copy audio stream\n",
    "            output_path\n",
    "        ]\n",
    "        \n",
    "        print(\"Step 2: Applying stabilization...\")\n",
    "        subprocess.run(stabilize_cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        \n",
    "        print(f\"Stabilization completed. Output saved to {output_path}\")\n",
    "        return True\n",
    "        \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error during FFmpeg processing: {e}\")\n",
    "        print(f\"Error output: {e.stderr.decode() if e.stderr else 'None'}\")\n",
    "        return False\n",
    "    finally:\n",
    "        # Clean up the temporary transform file\n",
    "        if os.path.exists(transform_file):\n",
    "            os.remove(transform_file)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"../data/NissanMurano/unstable.mp4\"\n",
    "    output_file = \"../data/NissanMurano/stable_max_smoothing.mp4\"\n",
    "    \n",
    "    # Make sure the output directory exists\n",
    "    output_dir = os.path.dirname(output_file)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Stabilize with max smooth quality parameters\n",
    "    stabilize_video_ffmpeg(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b56d3c7a-801e-4c1a-82c3-3693fd436c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 90 frames from ../data/NissanMurano/stable.mp4\n",
      "Extracted and fixed metadata for frame 1/90 - 0°\n",
      "Extracted and fixed metadata for frame 2/90 - 4°\n",
      "Extracted and fixed metadata for frame 3/90 - 8°\n",
      "Extracted and fixed metadata for frame 4/90 - 12°\n",
      "Extracted and fixed metadata for frame 5/90 - 16°\n",
      "Extracted and fixed metadata for frame 6/90 - 20°\n",
      "Extracted and fixed metadata for frame 7/90 - 24°\n",
      "Extracted and fixed metadata for frame 8/90 - 28°\n",
      "Extracted and fixed metadata for frame 9/90 - 32°\n",
      "Extracted and fixed metadata for frame 10/90 - 36°\n",
      "Extracted and fixed metadata for frame 11/90 - 40°\n",
      "Extracted and fixed metadata for frame 12/90 - 44°\n",
      "Extracted and fixed metadata for frame 13/90 - 48°\n",
      "Extracted and fixed metadata for frame 14/90 - 52°\n",
      "Extracted and fixed metadata for frame 15/90 - 56°\n",
      "Extracted and fixed metadata for frame 16/90 - 60°\n",
      "Extracted and fixed metadata for frame 17/90 - 64°\n",
      "Extracted and fixed metadata for frame 18/90 - 68°\n",
      "Extracted and fixed metadata for frame 19/90 - 72°\n",
      "Extracted and fixed metadata for frame 20/90 - 76°\n",
      "Extracted and fixed metadata for frame 21/90 - 80°\n",
      "Extracted and fixed metadata for frame 22/90 - 84°\n",
      "Extracted and fixed metadata for frame 23/90 - 88°\n",
      "Extracted and fixed metadata for frame 24/90 - 92°\n",
      "Extracted and fixed metadata for frame 25/90 - 96°\n",
      "Extracted and fixed metadata for frame 26/90 - 100°\n",
      "Extracted and fixed metadata for frame 27/90 - 104°\n",
      "Extracted and fixed metadata for frame 28/90 - 108°\n",
      "Extracted and fixed metadata for frame 29/90 - 112°\n",
      "Extracted and fixed metadata for frame 30/90 - 116°\n",
      "Extracted and fixed metadata for frame 31/90 - 120°\n",
      "Extracted and fixed metadata for frame 32/90 - 124°\n",
      "Extracted and fixed metadata for frame 33/90 - 128°\n",
      "Extracted and fixed metadata for frame 34/90 - 132°\n",
      "Extracted and fixed metadata for frame 35/90 - 136°\n",
      "Extracted and fixed metadata for frame 36/90 - 140°\n",
      "Extracted and fixed metadata for frame 37/90 - 144°\n",
      "Extracted and fixed metadata for frame 38/90 - 148°\n",
      "Extracted and fixed metadata for frame 39/90 - 152°\n",
      "Extracted and fixed metadata for frame 40/90 - 156°\n",
      "Extracted and fixed metadata for frame 41/90 - 160°\n",
      "Extracted and fixed metadata for frame 42/90 - 164°\n",
      "Extracted and fixed metadata for frame 43/90 - 168°\n",
      "Extracted and fixed metadata for frame 44/90 - 172°\n",
      "Extracted and fixed metadata for frame 45/90 - 176°\n",
      "Extracted and fixed metadata for frame 46/90 - 180°\n",
      "Extracted and fixed metadata for frame 47/90 - 184°\n",
      "Extracted and fixed metadata for frame 48/90 - 188°\n",
      "Extracted and fixed metadata for frame 49/90 - 192°\n",
      "Extracted and fixed metadata for frame 50/90 - 196°\n",
      "Extracted and fixed metadata for frame 51/90 - 200°\n",
      "Extracted and fixed metadata for frame 52/90 - 204°\n",
      "Extracted and fixed metadata for frame 53/90 - 208°\n",
      "Extracted and fixed metadata for frame 54/90 - 212°\n",
      "Extracted and fixed metadata for frame 55/90 - 216°\n",
      "Extracted and fixed metadata for frame 56/90 - 220°\n",
      "Extracted and fixed metadata for frame 57/90 - 224°\n",
      "Extracted and fixed metadata for frame 58/90 - 228°\n",
      "Extracted and fixed metadata for frame 59/90 - 232°\n",
      "Extracted and fixed metadata for frame 60/90 - 236°\n",
      "Extracted and fixed metadata for frame 61/90 - 240°\n",
      "Extracted and fixed metadata for frame 62/90 - 244°\n",
      "Extracted and fixed metadata for frame 63/90 - 248°\n",
      "Extracted and fixed metadata for frame 64/90 - 252°\n",
      "Extracted and fixed metadata for frame 65/90 - 256°\n",
      "Extracted and fixed metadata for frame 66/90 - 260°\n",
      "Extracted and fixed metadata for frame 67/90 - 264°\n",
      "Extracted and fixed metadata for frame 68/90 - 268°\n",
      "Extracted and fixed metadata for frame 69/90 - 272°\n",
      "Extracted and fixed metadata for frame 70/90 - 276°\n",
      "Extracted and fixed metadata for frame 71/90 - 280°\n",
      "Extracted and fixed metadata for frame 72/90 - 284°\n",
      "Extracted and fixed metadata for frame 73/90 - 288°\n",
      "Extracted and fixed metadata for frame 74/90 - 292°\n",
      "Extracted and fixed metadata for frame 75/90 - 296°\n",
      "Extracted and fixed metadata for frame 76/90 - 300°\n",
      "Extracted and fixed metadata for frame 77/90 - 304°\n",
      "Extracted and fixed metadata for frame 78/90 - 308°\n",
      "Extracted and fixed metadata for frame 79/90 - 312°\n",
      "Extracted and fixed metadata for frame 80/90 - 316°\n",
      "Extracted and fixed metadata for frame 81/90 - 320°\n",
      "Extracted and fixed metadata for frame 82/90 - 324°\n",
      "Extracted and fixed metadata for frame 83/90 - 328°\n",
      "Extracted and fixed metadata for frame 84/90 - 332°\n",
      "Extracted and fixed metadata for frame 85/90 - 336°\n",
      "Extracted and fixed metadata for frame 86/90 - 340°\n",
      "Extracted and fixed metadata for frame 87/90 - 344°\n",
      "Extracted and fixed metadata for frame 88/90 - 348°\n",
      "Extracted and fixed metadata for frame 89/90 - 352°\n",
      "Extracted and fixed metadata for frame 90/90 - 356°\n",
      "Extracted 90 frames with metadata for Meshroom.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import subprocess\n",
    "\n",
    "def inject_exif(image_path, camera_make=\"Samsung\", camera_model=\"Galaxy S21\", focal_length=\"4.5\", sensor_width=\"5.76\"):\n",
    "    \"\"\"\n",
    "    Injects smartphone-like EXIF metadata into an image for Meshroom.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the image file.\n",
    "        camera_make (str): Smartphone brand (e.g., Samsung, Apple)\n",
    "        camera_model (str): Smartphone model (e.g., iPhone 13, Pixel 6)\n",
    "        focal_length (str): Approximate focal length in mm.\n",
    "        sensor_width (str): Approximate sensor width in mm.\n",
    "    \"\"\"\n",
    "    cmd = [\n",
    "        \"exiftool\",\n",
    "        f\"-Make={camera_make}\",\n",
    "        f\"-Model={camera_model}\",\n",
    "        f\"-FocalLength={focal_length}\",\n",
    "        f\"-SensorWidth={sensor_width}\",\n",
    "        \"-overwrite_original\",\n",
    "        image_path\n",
    "    ]\n",
    "    subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "\n",
    "def extract_frames_with_metadata(input_path, output_dir, num_frames=90):\n",
    "    \"\"\"\n",
    "    Extract frames from a video at specific angles and inject metadata.\n",
    "\n",
    "    Args:\n",
    "        input_path (str): Path to input video\n",
    "        output_dir (str): Directory to save extracted frames\n",
    "        num_frames (int): Number of frames to extract\n",
    "\n",
    "    Returns:\n",
    "        list: Paths to extracted frames\n",
    "    \"\"\"\n",
    "    print(f\"Extracting {num_frames} frames from {input_path}\")\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Cannot open video file {input_path}\")\n",
    "        return []\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)\n",
    "    extracted_paths = []\n",
    "\n",
    "    for i, frame_idx in enumerate(frame_indices):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            angle = (i * 360) // num_frames\n",
    "            output_path = os.path.join(output_dir, f\"car{angle:03d}deg.jpg\")\n",
    "            cv2.imwrite(output_path, frame)\n",
    "\n",
    "            # Inject EXIF metadata for Meshroom\n",
    "            inject_exif(output_path)\n",
    "\n",
    "            extracted_paths.append(output_path)\n",
    "            print(f\"Extracted and fixed metadata for frame {i+1}/{num_frames} - {angle}°\")\n",
    "\n",
    "    cap.release()\n",
    "    return extracted_paths\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"../data/NissanMurano/stable.mp4\"\n",
    "    output_dir = \"../data/NissanMurano/frames\"\n",
    "\n",
    "    extracted_frames = extract_frames_with_metadata(input_file, output_dir, num_frames=90)\n",
    "    print(f\"Extracted {len(extracted_frames)} frames with metadata for Meshroom.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc5d7258-8f57-4f3b-815f-227aaabfff89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Stabilized video saved at: ../data/NissanMurano/stable_vidgear.mp4\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Uses the Vidgear library - is not that good.\n",
    "#\n",
    "\n",
    "import cv2\n",
    "from vidgear.gears.stabilizer import Stabilizer\n",
    "\n",
    "def stabilize_video_vidgear(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Stabilizes a shaky video using Vidgear's Stabilizer.\n",
    "\n",
    "    Parameters:\n",
    "        input_path (str): Path to the input shaky video.\n",
    "        output_path (str): Path to save the stabilized video.\n",
    "    \"\"\"\n",
    "    # Initialize Stabilizer with default parameters\n",
    "    stabilizer = Stabilizer()\n",
    "\n",
    "    # Open input video\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"❌ Error: Could not open video file.\")\n",
    "        return\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Initialize Video Writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for MP4\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    # Process each frame\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Stabilize frame\n",
    "        stable_frame = stabilizer.stabilize(frame)\n",
    "\n",
    "        # Write stabilized frame to output\n",
    "        if stable_frame is not None:\n",
    "            out.write(stable_frame)\n",
    "\n",
    "    print(f\"✅ Stabilized video saved at: {output_path}\")\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    stabilizer.clean()\n",
    "\n",
    "# Run stabilization\n",
    "input_video = \"../data/NissanMurano/unstable.mp4\"\n",
    "output_video = \"../data/NissanMurano/stable_vidgear.mp4\"\n",
    "stabilize_video_vidgear(input_video, output_video)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
